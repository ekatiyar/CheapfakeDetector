{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "third-halloween",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/drn'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-entrance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify.py train --arch drn_c_26 -j 4 /home/jupyter/dataset/ --epochs 10 --resume checkpoint_latest.pth.tar --lr .0001\n",
      "Namespace(arch='drn_c_26', batch_size=256, check_freq=10, cmd='train', crop_size=224, data='/home/jupyter/dataset/', epochs=10, evaluate=False, lr=0.0001, lr_adjust='step', momentum=0.9, num_classes=2, pretrained=False, print_freq=10, resume='checkpoint_latest.pth.tar', scale_size=256, start_epoch=0, step_ratio=0.1, weight_decay=0.0001, workers=4)\n",
      "=> loading checkpoint 'checkpoint_latest.pth.tar'\n",
      "=> loaded checkpoint 'checkpoint_latest.pth.tar' (epoch 1)\n",
      "{'modified': 0, 'original': 1}\n",
      "Epoch [1] Learning rate: 0.0001\n",
      "Epoch: [1][0/250]\tTime 35.611 (35.611)\tData 21.316 (21.316)\tLoss 0.3556 (0.3556)\tAcc 84.77\tPrec [98.73, 78.53]\n",
      "Epoch: [1][10/250]\tTime 0.521 (5.587)\tData 0.151 (3.900)\tLoss 0.4212 (0.3976)\tAcc 82.67\tPrec [96.02, 75.83]\n",
      "Epoch: [1][20/250]\tTime 16.908 (5.641)\tData 16.631 (4.573)\tLoss 0.4072 (0.3934)\tAcc 82.81\tPrec [96.92, 75.79]\n",
      "Epoch: [1][30/250]\tTime 2.025 (5.206)\tData 1.748 (4.354)\tLoss 0.3668 (0.3877)\tAcc 83.09\tPrec [96.73, 76.2]\n",
      "Epoch: [1][40/250]\tTime 15.069 (5.294)\tData 14.792 (4.553)\tLoss 0.3511 (0.3870)\tAcc 83.13\tPrec [96.94, 76.12]\n",
      "Epoch: [1][50/250]\tTime 4.521 (5.124)\tData 4.240 (4.449)\tLoss 0.3453 (0.3839)\tAcc 83.30\tPrec [97.11, 76.29]\n",
      "Epoch: [1][60/250]\tTime 15.380 (5.171)\tData 15.097 (4.540)\tLoss 0.3533 (0.3828)\tAcc 83.35\tPrec [97.2, 76.36]\n",
      "Epoch: [1][70/250]\tTime 2.887 (5.049)\tData 2.608 (4.451)\tLoss 0.3629 (0.3794)\tAcc 83.53\tPrec [97.23, 76.48]\n",
      "Epoch: [1][80/250]\tTime 15.985 (5.111)\tData 15.681 (4.537)\tLoss 0.3477 (0.3759)\tAcc 83.82\tPrec [97.24, 76.93]\n",
      "Epoch: [1][90/250]\tTime 3.062 (5.021)\tData 2.786 (4.466)\tLoss 0.4046 (0.3764)\tAcc 83.76\tPrec [97.23, 76.87]\n",
      "Epoch: [1][100/250]\tTime 12.480 (5.058)\tData 12.187 (4.518)\tLoss 0.3926 (0.3766)\tAcc 83.76\tPrec [97.16, 76.87]\n",
      "Epoch: [1][110/250]\tTime 5.969 (5.020)\tData 5.672 (4.493)\tLoss 0.4027 (0.3756)\tAcc 83.82\tPrec [97.16, 76.99]\n",
      "Epoch: [1][120/250]\tTime 13.021 (5.038)\tData 12.717 (4.521)\tLoss 0.3515 (0.3738)\tAcc 83.89\tPrec [97.28, 76.96]\n",
      "Epoch: [1][130/250]\tTime 6.845 (5.001)\tData 6.547 (4.493)\tLoss 0.3713 (0.3715)\tAcc 84.04\tPrec [97.33, 77.1]\n",
      "Epoch: [1][140/250]\tTime 12.336 (5.020)\tData 12.041 (4.519)\tLoss 0.3765 (0.3711)\tAcc 84.06\tPrec [97.36, 77.12]\n",
      "Epoch: [1][150/250]\tTime 7.061 (4.999)\tData 6.784 (4.505)\tLoss 0.3715 (0.3705)\tAcc 84.08\tPrec [97.43, 77.09]\n",
      "Epoch: [1][160/250]\tTime 11.522 (5.009)\tData 11.228 (4.521)\tLoss 0.3394 (0.3689)\tAcc 84.18\tPrec [97.5, 77.18]\n",
      "Epoch: [1][170/250]\tTime 7.216 (4.996)\tData 6.941 (4.513)\tLoss 0.3298 (0.3671)\tAcc 84.28\tPrec [97.5, 77.33]\n",
      "Epoch: [1][180/250]\tTime 10.735 (5.002)\tData 10.451 (4.524)\tLoss 0.3568 (0.3659)\tAcc 84.36\tPrec [97.55, 77.4]\n",
      "Epoch: [1][190/250]\tTime 6.701 (4.988)\tData 6.424 (4.514)\tLoss 0.3034 (0.3650)\tAcc 84.43\tPrec [97.6, 77.5]\n",
      "Epoch: [1][200/250]\tTime 9.148 (4.996)\tData 8.872 (4.525)\tLoss 0.3804 (0.3645)\tAcc 84.43\tPrec [97.66, 77.46]\n",
      "Epoch: [1][210/250]\tTime 8.608 (4.990)\tData 8.333 (4.523)\tLoss 0.4100 (0.3630)\tAcc 84.54\tPrec [97.65, 77.6]\n",
      "Epoch: [1][220/250]\tTime 9.607 (4.988)\tData 9.324 (4.523)\tLoss 0.3629 (0.3624)\tAcc 84.57\tPrec [97.68, 77.63]\n",
      "Epoch: [1][230/250]\tTime 8.793 (4.989)\tData 8.517 (4.531)\tLoss 0.3468 (0.3614)\tAcc 84.63\tPrec [97.66, 77.72]\n",
      "Epoch: [1][240/250]\tTime 7.910 (4.982)\tData 7.634 (4.528)\tLoss 0.4228 (0.3605)\tAcc 84.67\tPrec [97.62, 77.77]\n",
      "Test: [0/63]\tTime 11.972 (11.972)\tLoss 0.4851 (0.4851)\tAcc 69.92\tPrec [100.0, 0.0]\n",
      "Test: [10/63]\tTime 0.168 (4.630)\tLoss 0.4836 (0.4758)\tAcc 70.31\tPrec [100.0, 0.0]\n",
      "Test: [20/63]\tTime 16.676 (4.901)\tLoss 0.5236 (0.4735)\tAcc 70.20\tPrec [100.0, 0.0]\n",
      "Test: [30/63]\tTime 0.195 (4.466)\tLoss 0.2834 (0.4705)\tAcc 70.59\tPrec [99.98, 7.49]\n",
      "Test: [40/63]\tTime 16.533 (4.706)\tLoss 0.2170 (0.4113)\tAcc 77.60\tPrec [99.67, 53.94]\n",
      "Test: [50/63]\tTime 0.170 (4.580)\tLoss 0.2311 (0.3758)\tAcc 81.86\tPrec [99.36, 69.33]\n",
      "Test: [60/63]\tTime 15.168 (4.671)\tLoss 0.2257 (0.3521)\tAcc 84.71\tPrec [98.99, 77.01]\n",
      " * Acc 85.05\tPrec [98.94, 77.82]\n",
      "Epoch [2] Learning rate: 0.0001\n",
      "Epoch: [2][0/250]\tTime 20.275 (20.275)\tData 19.780 (19.780)\tLoss 0.3233 (0.3233)\tAcc 86.33\tPrec [97.98, 78.98]\n",
      "Epoch: [2][10/250]\tTime 0.515 (5.663)\tData 0.000 (5.189)\tLoss 0.3466 (0.3353)\tAcc 85.87\tPrec [98.83, 78.47]\n",
      "Epoch: [2][20/250]\tTime 17.773 (5.792)\tData 17.473 (5.329)\tLoss 0.3245 (0.3353)\tAcc 86.05\tPrec [98.17, 79.37]\n",
      "Epoch: [2][30/250]\tTime 0.515 (5.219)\tData 0.000 (4.754)\tLoss 0.3129 (0.3406)\tAcc 85.81\tPrec [97.77, 79.21]\n",
      "Epoch: [2][40/250]\tTime 18.980 (5.412)\tData 18.700 (4.951)\tLoss 0.3581 (0.3408)\tAcc 85.81\tPrec [97.74, 79.16]\n",
      "Epoch: [2][50/250]\tTime 0.517 (5.148)\tData 0.000 (4.685)\tLoss 0.3452 (0.3407)\tAcc 85.80\tPrec [97.93, 79.09]\n",
      "Epoch: [2][60/250]\tTime 18.526 (5.268)\tData 18.249 (4.807)\tLoss 0.3512 (0.3379)\tAcc 85.90\tPrec [97.75, 79.28]\n",
      "Epoch: [2][70/250]\tTime 0.515 (5.111)\tData 0.000 (4.650)\tLoss 0.3402 (0.3372)\tAcc 85.92\tPrec [97.82, 79.25]\n",
      "Epoch: [2][80/250]\tTime 17.847 (5.185)\tData 17.556 (4.725)\tLoss 0.2974 (0.3353)\tAcc 86.03\tPrec [97.87, 79.39]\n",
      "Epoch: [2][90/250]\tTime 0.524 (5.052)\tData 0.000 (4.591)\tLoss 0.3661 (0.3330)\tAcc 86.20\tPrec [97.9, 79.67]\n",
      "Epoch: [2][100/250]\tTime 18.801 (5.126)\tData 18.510 (4.665)\tLoss 0.3511 (0.3311)\tAcc 86.31\tPrec [97.86, 79.83]\n",
      "Epoch: [2][110/250]\tTime 1.043 (5.032)\tData 0.766 (4.574)\tLoss 0.2944 (0.3303)\tAcc 86.29\tPrec [97.9, 79.77]\n",
      "Epoch: [2][120/250]\tTime 18.678 (5.101)\tData 18.382 (4.649)\tLoss 0.3124 (0.3288)\tAcc 86.38\tPrec [97.95, 79.85]\n",
      "Epoch: [2][130/250]\tTime 0.515 (5.020)\tData 0.200 (4.567)\tLoss 0.3108 (0.3276)\tAcc 86.47\tPrec [97.91, 79.98]\n",
      "Epoch: [2][140/250]\tTime 17.648 (5.083)\tData 17.355 (4.634)\tLoss 0.3210 (0.3268)\tAcc 86.51\tPrec [97.91, 80.03]\n",
      "Epoch: [2][150/250]\tTime 0.700 (5.016)\tData 0.416 (4.570)\tLoss 0.2925 (0.3257)\tAcc 86.57\tPrec [97.92, 80.1]\n",
      "Epoch: [2][160/250]\tTime 19.063 (5.074)\tData 18.736 (4.629)\tLoss 0.3075 (0.3261)\tAcc 86.55\tPrec [97.92, 80.07]\n",
      "Epoch: [2][170/250]\tTime 0.515 (5.013)\tData 0.000 (4.567)\tLoss 0.3531 (0.3251)\tAcc 86.63\tPrec [97.95, 80.18]\n",
      "Epoch: [2][180/250]\tTime 18.164 (5.064)\tData 17.873 (4.620)\tLoss 0.3650 (0.3246)\tAcc 86.66\tPrec [97.96, 80.22]\n",
      "Epoch: [2][190/250]\tTime 0.518 (5.012)\tData 0.000 (4.567)\tLoss 0.3753 (0.3246)\tAcc 86.64\tPrec [97.97, 80.17]\n",
      "Epoch: [2][200/250]\tTime 18.638 (5.056)\tData 18.358 (4.612)\tLoss 0.2806 (0.3241)\tAcc 86.68\tPrec [98.0, 80.21]\n",
      "Epoch: [2][210/250]\tTime 0.515 (5.009)\tData 0.000 (4.564)\tLoss 0.3533 (0.3247)\tAcc 86.64\tPrec [98.02, 80.13]\n",
      "Epoch: [2][220/250]\tTime 18.250 (5.048)\tData 17.954 (4.603)\tLoss 0.3442 (0.3251)\tAcc 86.60\tPrec [98.01, 80.07]\n",
      "Epoch: [2][230/250]\tTime 0.522 (4.998)\tData 0.001 (4.551)\tLoss 0.3103 (0.3251)\tAcc 86.60\tPrec [98.02, 80.06]\n",
      "Epoch: [2][240/250]\tTime 18.019 (5.030)\tData 17.727 (4.585)\tLoss 0.2811 (0.3248)\tAcc 86.62\tPrec [98.03, 80.07]\n",
      "Test: [0/63]\tTime 12.151 (12.151)\tLoss 0.5404 (0.5404)\tAcc 72.66\tPrec [100.0, 0.0]\n",
      "Test: [10/63]\tTime 0.170 (4.468)\tLoss 0.5170 (0.5555)\tAcc 73.51\tPrec [100.0, 0.0]\n",
      "Test: [20/63]\tTime 17.322 (4.851)\tLoss 0.6233 (0.5605)\tAcc 73.10\tPrec [100.0, 0.0]\n",
      "Test: [30/63]\tTime 0.171 (4.395)\tLoss 0.2716 (0.5581)\tAcc 73.34\tPrec [99.98, 8.2]\n",
      "Test: [40/63]\tTime 16.959 (4.672)\tLoss 0.1241 (0.4534)\tAcc 79.74\tPrec [99.79, 56.42]\n",
      "Test: [50/63]\tTime 0.169 (4.518)\tLoss 0.1228 (0.3899)\tAcc 83.61\tPrec [99.56, 71.42]\n",
      "Test: [60/63]\tTime 14.753 (4.607)\tLoss 0.1259 (0.3473)\tAcc 86.21\tPrec [99.31, 78.74]\n",
      " * Acc 86.52\tPrec [99.28, 79.5]\n",
      "Epoch [3] Learning rate: 0.0001\n",
      "Epoch: [3][0/250]\tTime 19.827 (19.827)\tData 19.531 (19.531)\tLoss 0.3298 (0.3298)\tAcc 85.94\tPrec [99.02, 77.27]\n",
      "Epoch: [3][10/250]\tTime 0.516 (5.546)\tData 0.000 (5.090)\tLoss 0.3336 (0.3110)\tAcc 87.18\tPrec [98.6, 80.17]\n",
      "Epoch: [3][20/250]\tTime 18.859 (5.728)\tData 18.567 (5.285)\tLoss 0.3104 (0.3071)\tAcc 87.26\tPrec [98.49, 80.29]\n",
      "Epoch: [3][30/250]\tTime 0.536 (5.161)\tData 0.251 (4.723)\tLoss 0.3033 (0.3065)\tAcc 87.15\tPrec [98.34, 80.32]\n",
      "Epoch: [3][40/250]\tTime 18.021 (5.335)\tData 17.729 (4.895)\tLoss 0.3085 (0.3063)\tAcc 87.31\tPrec [98.33, 80.68]\n",
      "Epoch: [3][50/250]\tTime 0.515 (5.090)\tData 0.000 (4.644)\tLoss 0.3608 (0.3069)\tAcc 87.27\tPrec [98.28, 80.68]\n",
      "Epoch: [3][60/250]\tTime 17.861 (5.211)\tData 17.585 (4.768)\tLoss 0.3271 (0.3069)\tAcc 87.26\tPrec [98.27, 80.71]\n",
      "Epoch: [3][70/250]\tTime 0.524 (5.044)\tData 0.076 (4.604)\tLoss 0.3614 (0.3073)\tAcc 87.26\tPrec [98.22, 80.75]\n",
      "Epoch: [3][80/250]\tTime 19.065 (5.160)\tData 18.743 (4.718)\tLoss 0.2559 (0.3047)\tAcc 87.44\tPrec [98.27, 80.98]\n",
      "Epoch: [3][90/250]\tTime 0.514 (5.025)\tData 0.165 (4.582)\tLoss 0.3438 (0.3068)\tAcc 87.32\tPrec [98.02, 80.96]\n",
      "Epoch: [3][100/250]\tTime 18.170 (5.107)\tData 17.874 (4.663)\tLoss 0.3395 (0.3084)\tAcc 87.21\tPrec [97.94, 80.83]\n",
      "Epoch: [3][110/250]\tTime 0.521 (5.009)\tData 0.000 (4.563)\tLoss 0.3442 (0.3097)\tAcc 87.17\tPrec [97.94, 80.79]\n",
      "Epoch: [3][120/250]\tTime 18.201 (5.069)\tData 17.910 (4.623)\tLoss 0.2376 (0.3080)\tAcc 87.26\tPrec [98.01, 80.9]\n",
      "Epoch: [3][130/250]\tTime 0.513 (4.990)\tData 0.000 (4.544)\tLoss 0.3543 (0.3088)\tAcc 87.23\tPrec [98.02, 80.83]\n",
      "Epoch: [3][140/250]\tTime 17.856 (5.050)\tData 17.539 (4.603)\tLoss 0.3398 (0.3100)\tAcc 87.17\tPrec [98.02, 80.76]\n",
      "Epoch: [3][150/250]\tTime 2.021 (4.987)\tData 1.745 (4.541)\tLoss 0.2964 (0.3107)\tAcc 87.15\tPrec [98.01, 80.72]\n",
      "Epoch: [3][160/250]\tTime 17.571 (5.033)\tData 17.273 (4.591)\tLoss 0.3305 (0.3102)\tAcc 87.15\tPrec [98.02, 80.7]\n",
      "Epoch: [3][170/250]\tTime 1.907 (4.982)\tData 1.629 (4.541)\tLoss 0.2734 (0.3103)\tAcc 87.15\tPrec [98.06, 80.7]\n",
      "Epoch: [3][180/250]\tTime 17.427 (5.022)\tData 17.127 (4.583)\tLoss 0.2913 (0.3092)\tAcc 87.22\tPrec [98.06, 80.78]\n",
      "Epoch: [3][190/250]\tTime 0.515 (4.972)\tData 0.000 (4.535)\tLoss 0.3076 (0.3089)\tAcc 87.23\tPrec [98.06, 80.81]\n",
      "Epoch: [3][200/250]\tTime 18.279 (5.018)\tData 18.004 (4.579)\tLoss 0.2615 (0.3084)\tAcc 87.26\tPrec [98.08, 80.85]\n",
      "Epoch: [3][210/250]\tTime 0.519 (4.974)\tData 0.000 (4.534)\tLoss 0.3154 (0.3081)\tAcc 87.29\tPrec [98.04, 80.9]\n",
      "Epoch: [3][220/250]\tTime 18.104 (5.016)\tData 17.807 (4.576)\tLoss 0.3093 (0.3080)\tAcc 87.30\tPrec [98.08, 80.92]\n",
      "Epoch: [3][230/250]\tTime 0.514 (4.977)\tData 0.000 (4.536)\tLoss 0.2974 (0.3080)\tAcc 87.30\tPrec [98.06, 80.94]\n",
      "Epoch: [3][240/250]\tTime 19.388 (5.020)\tData 19.094 (4.578)\tLoss 0.3079 (0.3079)\tAcc 87.28\tPrec [98.05, 80.91]\n",
      "Test: [0/63]\tTime 12.393 (12.393)\tLoss 0.4023 (0.4023)\tAcc 74.61\tPrec [100.0, 0.0]\n",
      "Test: [10/63]\tTime 0.176 (4.543)\tLoss 0.3896 (0.4252)\tAcc 75.67\tPrec [100.0, 0.0]\n",
      "Test: [20/63]\tTime 15.479 (4.798)\tLoss 0.4647 (0.4271)\tAcc 75.33\tPrec [100.0, 0.0]\n",
      "Test: [30/63]\tTime 0.170 (4.379)\tLoss 0.2708 (0.4241)\tAcc 75.34\tPrec [99.93, 8.7]\n",
      "Test: [40/63]\tTime 16.003 (4.612)\tLoss 0.1796 (0.3675)\tAcc 81.14\tPrec [99.54, 58.23]\n",
      "Test: [50/63]\tTime 0.170 (4.499)\tLoss 0.2092 (0.3343)\tAcc 84.63\tPrec [99.08, 72.91]\n",
      "Test: [60/63]\tTime 14.459 (4.577)\tLoss 0.2053 (0.3122)\tAcc 86.99\tPrec [98.65, 79.96]\n",
      " * Acc 87.27\tPrec [98.59, 80.69]\n",
      "Epoch [4] Learning rate: 0.0001\n",
      "Epoch: [4][0/250]\tTime 19.343 (19.343)\tData 19.043 (19.043)\tLoss 0.3231 (0.3231)\tAcc 85.16\tPrec [97.75, 78.44]\n",
      "Epoch: [4][10/250]\tTime 0.515 (5.433)\tData 0.000 (4.975)\tLoss 0.3286 (0.2915)\tAcc 87.68\tPrec [97.18, 81.61]\n",
      "Epoch: [4][20/250]\tTime 18.095 (5.649)\tData 17.805 (5.204)\tLoss 0.4085 (0.2932)\tAcc 87.48\tPrec [96.43, 81.47]\n",
      "Epoch: [4][30/250]\tTime 0.515 (5.094)\tData 0.000 (4.656)\tLoss 0.2845 (0.2920)\tAcc 87.46\tPrec [96.87, 81.24]\n",
      "Epoch: [4][40/250]\tTime 17.758 (5.272)\tData 17.462 (4.842)\tLoss 0.2710 (0.2896)\tAcc 87.79\tPrec [96.87, 81.84]\n",
      "Epoch: [4][50/250]\tTime 0.516 (5.036)\tData 0.000 (4.607)\tLoss 0.2759 (0.2925)\tAcc 87.60\tPrec [96.94, 81.55]\n",
      "Epoch: [4][60/250]\tTime 17.369 (5.161)\tData 17.075 (4.728)\tLoss 0.2627 (0.2947)\tAcc 87.54\tPrec [96.94, 81.49]\n",
      "Epoch: [4][70/250]\tTime 0.518 (5.017)\tData 0.000 (4.589)\tLoss 0.2775 (0.2931)\tAcc 87.72\tPrec [97.11, 81.76]\n",
      "Epoch: [4][80/250]\tTime 16.819 (5.096)\tData 16.525 (4.671)\tLoss 0.2947 (0.2950)\tAcc 87.65\tPrec [97.05, 81.71]\n",
      "Epoch: [4][90/250]\tTime 0.518 (5.012)\tData 0.000 (4.589)\tLoss 0.3164 (0.2959)\tAcc 87.59\tPrec [97.01, 81.67]\n",
      "Epoch: [4][100/250]\tTime 15.944 (5.071)\tData 15.657 (4.651)\tLoss 0.2930 (0.2957)\tAcc 87.56\tPrec [97.12, 81.54]\n",
      "Epoch: [4][110/250]\tTime 0.519 (4.994)\tData 0.000 (4.576)\tLoss 0.2789 (0.2941)\tAcc 87.70\tPrec [97.17, 81.78]\n",
      "Epoch: [4][120/250]\tTime 15.997 (5.050)\tData 15.702 (4.633)\tLoss 0.2885 (0.2940)\tAcc 87.76\tPrec [97.32, 81.83]\n",
      "Epoch: [4][130/250]\tTime 0.516 (4.994)\tData 0.000 (4.578)\tLoss 0.3285 (0.2937)\tAcc 87.77\tPrec [97.24, 81.89]\n",
      "Epoch: [4][140/250]\tTime 15.826 (5.036)\tData 15.530 (4.621)\tLoss 0.2996 (0.2929)\tAcc 87.84\tPrec [97.28, 81.98]\n",
      "Epoch: [4][150/250]\tTime 0.513 (4.985)\tData 0.000 (4.571)\tLoss 0.3239 (0.2927)\tAcc 87.84\tPrec [97.33, 81.95]\n",
      "Epoch: [4][160/250]\tTime 16.368 (5.029)\tData 16.073 (4.616)\tLoss 0.3115 (0.2930)\tAcc 87.84\tPrec [97.33, 81.97]\n",
      "Epoch: [4][170/250]\tTime 0.513 (4.985)\tData 0.000 (4.573)\tLoss 0.3222 (0.2935)\tAcc 87.81\tPrec [97.39, 81.9]\n",
      "Epoch: [4][180/250]\tTime 16.705 (5.021)\tData 16.411 (4.609)\tLoss 0.2754 (0.2932)\tAcc 87.84\tPrec [97.44, 81.93]\n",
      "Epoch: [4][190/250]\tTime 0.517 (4.980)\tData 0.000 (4.569)\tLoss 0.2533 (0.2925)\tAcc 87.86\tPrec [97.44, 81.95]\n",
      "Epoch: [4][200/250]\tTime 16.425 (5.012)\tData 16.126 (4.601)\tLoss 0.2271 (0.2927)\tAcc 87.84\tPrec [97.3, 81.96]\n",
      "Epoch: [4][210/250]\tTime 0.518 (4.977)\tData 0.000 (4.567)\tLoss 0.3240 (0.2934)\tAcc 87.79\tPrec [97.35, 81.88]\n",
      "Epoch: [4][220/250]\tTime 16.203 (5.006)\tData 15.907 (4.596)\tLoss 0.2787 (0.2937)\tAcc 87.78\tPrec [97.34, 81.87]\n",
      "Epoch: [4][230/250]\tTime 0.519 (4.976)\tData 0.000 (4.566)\tLoss 0.3059 (0.2937)\tAcc 87.78\tPrec [97.39, 81.85]\n",
      "Epoch: [4][240/250]\tTime 14.409 (4.996)\tData 14.113 (4.587)\tLoss 0.2915 (0.2938)\tAcc 87.78\tPrec [97.4, 81.84]\n",
      "Test: [0/63]\tTime 12.821 (12.821)\tLoss 0.3551 (0.3551)\tAcc 78.52\tPrec [100.0, 0.0]\n",
      "Test: [10/63]\tTime 0.173 (4.647)\tLoss 0.3248 (0.3669)\tAcc 77.66\tPrec [100.0, 0.0]\n",
      "Test: [20/63]\tTime 15.817 (4.880)\tLoss 0.3958 (0.3716)\tAcc 77.51\tPrec [100.0, 0.0]\n",
      "Test: [30/63]\tTime 0.170 (4.405)\tLoss 0.2979 (0.3727)\tAcc 77.52\tPrec [99.88, 9.34]\n",
      "Test: [40/63]\tTime 13.202 (4.622)\tLoss 0.2255 (0.3385)\tAcc 82.42\tPrec [98.87, 60.15]\n",
      "Test: [50/63]\tTime 0.170 (4.543)\tLoss 0.2324 (0.3176)\tAcc 85.33\tPrec [97.74, 74.43]\n",
      "Test: [60/63]\tTime 11.839 (4.595)\tLoss 0.2508 (0.3040)\tAcc 87.33\tPrec [96.74, 81.19]\n",
      " * Acc 87.57\tPrec [96.6, 81.89]\n",
      "Epoch [5] Learning rate: 0.0001\n",
      "Epoch: [5][0/250]\tTime 19.312 (19.312)\tData 19.022 (19.022)\tLoss 0.2807 (0.2807)\tAcc 89.45\tPrec [98.15, 83.11]\n",
      "Epoch: [5][10/250]\tTime 0.517 (5.422)\tData 0.000 (4.966)\tLoss 0.2557 (0.2533)\tAcc 89.77\tPrec [97.21, 84.67]\n",
      "Epoch: [5][20/250]\tTime 17.483 (5.553)\tData 17.207 (5.122)\tLoss 0.3183 (0.2571)\tAcc 89.21\tPrec [97.33, 83.72]\n",
      "Epoch: [5][30/250]\tTime 0.515 (5.088)\tData 0.001 (4.670)\tLoss 0.2831 (0.2606)\tAcc 89.09\tPrec [96.93, 83.71]\n",
      "Epoch: [5][40/250]\tTime 16.400 (5.225)\tData 16.124 (4.824)\tLoss 0.2612 (0.2667)\tAcc 88.77\tPrec [97.09, 83.23]\n",
      "Epoch: [5][50/250]\tTime 0.518 (4.994)\tData 0.128 (4.610)\tLoss 0.2443 (0.2665)\tAcc 88.85\tPrec [96.93, 83.48]\n",
      "Epoch: [5][60/250]\tTime 17.035 (5.123)\tData 16.734 (4.749)\tLoss 0.2733 (0.2698)\tAcc 88.63\tPrec [96.73, 83.25]\n",
      "Epoch: [5][70/250]\tTime 1.353 (4.991)\tData 1.075 (4.623)\tLoss 0.2926 (0.2698)\tAcc 88.68\tPrec [96.68, 83.39]\n",
      "Epoch: [5][80/250]\tTime 16.720 (5.071)\tData 16.425 (4.702)\tLoss 0.2883 (0.2719)\tAcc 88.59\tPrec [96.85, 83.18]\n",
      "Epoch: [5][90/250]\tTime 1.939 (4.980)\tData 1.662 (4.607)\tLoss 0.2713 (0.2721)\tAcc 88.55\tPrec [96.69, 83.24]\n",
      "Epoch: [5][100/250]\tTime 17.039 (5.044)\tData 16.742 (4.668)\tLoss 0.2474 (0.2717)\tAcc 88.59\tPrec [96.73, 83.28]\n",
      "Epoch: [5][110/250]\tTime 0.516 (4.956)\tData 0.000 (4.584)\tLoss 0.2897 (0.2738)\tAcc 88.51\tPrec [96.65, 83.18]\n",
      "Epoch: [5][120/250]\tTime 16.579 (5.014)\tData 16.281 (4.647)\tLoss 0.2784 (0.2737)\tAcc 88.51\tPrec [96.57, 83.2]\n",
      "Epoch: [5][130/250]\tTime 0.516 (4.952)\tData 0.000 (4.583)\tLoss 0.2114 (0.2727)\tAcc 88.56\tPrec [96.65, 83.25]\n",
      "Epoch: [5][140/250]\tTime 16.828 (4.998)\tData 16.532 (4.626)\tLoss 0.2505 (0.2727)\tAcc 88.55\tPrec [96.57, 83.27]\n",
      "Epoch: [5][150/250]\tTime 0.514 (4.982)\tData 0.000 (4.608)\tLoss 0.3112 (0.2737)\tAcc 88.48\tPrec [96.51, 83.2]\n",
      "Epoch: [5][160/250]\tTime 21.495 (5.091)\tData 21.207 (4.714)\tLoss 0.3523 (0.2755)\tAcc 88.36\tPrec [96.37, 83.09]\n",
      "Epoch: [5][170/250]\tTime 0.530 (5.067)\tData 0.000 (4.685)\tLoss 0.3205 (0.2762)\tAcc 88.34\tPrec [96.4, 83.04]\n",
      "Epoch: [5][180/250]\tTime 21.700 (5.167)\tData 21.404 (4.781)\tLoss 0.2125 (0.2756)\tAcc 88.37\tPrec [96.37, 83.11]\n",
      "Epoch: [5][190/250]\tTime 0.516 (5.140)\tData 0.000 (4.749)\tLoss 0.2317 (0.2759)\tAcc 88.36\tPrec [96.36, 83.09]\n",
      "Epoch: [5][200/250]\tTime 21.616 (5.217)\tData 21.322 (4.824)\tLoss 0.2508 (0.2760)\tAcc 88.35\tPrec [96.37, 83.08]\n",
      "Epoch: [5][210/250]\tTime 0.515 (5.194)\tData 0.000 (4.796)\tLoss 0.3079 (0.2766)\tAcc 88.34\tPrec [96.35, 83.08]\n",
      "Epoch: [5][220/250]\tTime 21.424 (5.267)\tData 21.136 (4.868)\tLoss 0.2297 (0.2772)\tAcc 88.31\tPrec [96.37, 83.03]\n",
      "Epoch: [5][230/250]\tTime 0.514 (5.241)\tData 0.000 (4.838)\tLoss 0.2932 (0.2775)\tAcc 88.29\tPrec [96.37, 83.0]\n",
      "Epoch: [5][240/250]\tTime 21.979 (5.309)\tData 21.674 (4.904)\tLoss 0.2797 (0.2783)\tAcc 88.24\tPrec [96.33, 82.96]\n",
      "Test: [0/63]\tTime 11.983 (11.983)\tLoss 0.1903 (0.1903)\tAcc 88.28\tPrec [100.0, 0.0]\n",
      "Test: [10/63]\tTime 0.172 (4.737)\tLoss 0.1942 (0.2222)\tAcc 85.58\tPrec [100.0, 0.0]\n",
      "Test: [20/63]\tTime 17.413 (5.392)\tLoss 0.2299 (0.2229)\tAcc 85.71\tPrec [100.0, 0.0]\n",
      "Test: [30/63]\tTime 0.168 (5.203)\tLoss 0.4166 (0.2311)\tAcc 85.46\tPrec [99.58, 12.58]\n",
      "Test: [40/63]\tTime 16.465 (5.580)\tLoss 0.4426 (0.2867)\tAcc 84.58\tPrec [93.08, 66.73]\n",
      "Test: [50/63]\tTime 2.767 (5.499)\tLoss 0.4708 (0.3202)\tAcc 84.31\tPrec [87.78, 79.58]\n",
      "Test: [60/63]\tTime 10.173 (5.630)\tLoss 0.4679 (0.3430)\tAcc 84.14\tPrec [83.06, 85.27]\n",
      " * Acc 84.17\tPrec [82.48, 85.86]\n",
      "Epoch [6] Learning rate: 0.0001\n",
      "Epoch: [6][0/250]\tTime 23.151 (23.151)\tData 22.859 (22.859)\tLoss 0.2964 (0.2964)\tAcc 87.50\tPrec [96.77, 82.21]\n",
      "Epoch: [6][10/250]\tTime 0.513 (6.456)\tData 0.000 (6.000)\tLoss 0.2372 (0.2566)\tAcc 89.74\tPrec [96.71, 85.09]\n",
      "Epoch: [6][20/250]\tTime 21.057 (6.599)\tData 20.766 (6.156)\tLoss 0.2979 (0.2644)\tAcc 88.84\tPrec [96.66, 83.6]\n",
      "Epoch: [6][30/250]\tTime 0.512 (5.984)\tData 0.000 (5.532)\tLoss 0.2723 (0.2627)\tAcc 88.94\tPrec [96.37, 83.91]\n",
      "Epoch: [6][40/250]\tTime 21.495 (6.184)\tData 21.201 (5.733)\tLoss 0.2226 (0.2612)\tAcc 89.01\tPrec [96.23, 84.1]\n",
      "Epoch: [6][50/250]\tTime 0.515 (5.910)\tData 0.000 (5.455)\tLoss 0.2163 (0.2583)\tAcc 89.01\tPrec [96.08, 84.21]\n",
      "Epoch: [6][60/250]\tTime 21.668 (6.036)\tData 21.377 (5.581)\tLoss 0.3076 (0.2579)\tAcc 88.89\tPrec [95.44, 84.42]\n",
      "Epoch: [6][70/250]\tTime 0.514 (5.839)\tData 0.000 (5.382)\tLoss 0.2071 (0.2606)\tAcc 88.75\tPrec [95.61, 84.12]\n",
      "Epoch: [6][80/250]\tTime 21.665 (5.957)\tData 21.370 (5.501)\tLoss 0.2341 (0.2606)\tAcc 88.87\tPrec [95.75, 84.18]\n",
      "Epoch: [6][90/250]\tTime 0.516 (5.822)\tData 0.000 (5.364)\tLoss 0.2390 (0.2575)\tAcc 89.04\tPrec [95.6, 84.53]\n",
      "Epoch: [6][100/250]\tTime 20.712 (5.898)\tData 20.424 (5.441)\tLoss 0.2383 (0.2574)\tAcc 89.03\tPrec [95.63, 84.47]\n",
      "Epoch: [6][110/250]\tTime 0.515 (5.788)\tData 0.000 (5.330)\tLoss 0.2592 (0.2601)\tAcc 88.83\tPrec [95.49, 84.26]\n",
      "Epoch: [6][120/250]\tTime 21.351 (5.865)\tData 21.057 (5.407)\tLoss 0.2979 (0.2606)\tAcc 88.84\tPrec [95.56, 84.21]\n",
      "Epoch: [6][130/250]\tTime 0.514 (5.771)\tData 0.000 (5.312)\tLoss 0.3353 (0.2604)\tAcc 88.87\tPrec [95.57, 84.28]\n",
      "Epoch: [6][140/250]\tTime 21.223 (5.847)\tData 20.923 (5.388)\tLoss 0.3068 (0.2616)\tAcc 88.85\tPrec [95.54, 84.28]\n",
      "Epoch: [6][150/250]\tTime 0.513 (5.764)\tData 0.000 (5.304)\tLoss 0.2701 (0.2625)\tAcc 88.79\tPrec [95.5, 84.2]\n",
      "Epoch: [6][160/250]\tTime 20.823 (5.821)\tData 20.526 (5.363)\tLoss 0.2459 (0.2627)\tAcc 88.73\tPrec [95.45, 84.12]\n",
      "Epoch: [6][170/250]\tTime 0.515 (5.760)\tData 0.000 (5.300)\tLoss 0.2174 (0.2635)\tAcc 88.65\tPrec [95.43, 84.01]\n",
      "Epoch: [6][180/250]\tTime 21.389 (5.811)\tData 21.086 (5.352)\tLoss 0.3949 (0.2638)\tAcc 88.63\tPrec [95.43, 83.97]\n",
      "Epoch: [6][190/250]\tTime 0.518 (5.753)\tData 0.000 (5.296)\tLoss 0.2466 (0.2644)\tAcc 88.58\tPrec [95.32, 83.95]\n",
      "Epoch: [6][200/250]\tTime 19.436 (5.795)\tData 19.141 (5.341)\tLoss 0.2627 (0.2650)\tAcc 88.56\tPrec [95.39, 83.88]\n",
      "Epoch: [6][210/250]\tTime 0.514 (5.750)\tData 0.000 (5.298)\tLoss 0.2306 (0.2649)\tAcc 88.58\tPrec [95.39, 83.9]\n",
      "Epoch: [6][220/250]\tTime 18.874 (5.785)\tData 18.578 (5.335)\tLoss 0.2383 (0.2646)\tAcc 88.63\tPrec [95.46, 83.94]\n",
      "Epoch: [6][230/250]\tTime 0.522 (5.749)\tData 0.000 (5.302)\tLoss 0.2626 (0.2648)\tAcc 88.61\tPrec [95.41, 83.93]\n",
      "Epoch: [6][240/250]\tTime 17.570 (5.775)\tData 17.279 (5.329)\tLoss 0.2915 (0.2647)\tAcc 88.62\tPrec [95.4, 83.95]\n",
      "Test: [0/63]\tTime 11.943 (11.943)\tLoss 0.2768 (0.2768)\tAcc 83.59\tPrec [100.0, 0.0]\n",
      "Test: [10/63]\tTime 0.170 (4.824)\tLoss 0.2887 (0.3353)\tAcc 81.29\tPrec [100.0, 0.0]\n",
      "Test: [20/63]\tTime 20.458 (5.603)\tLoss 0.3505 (0.3383)\tAcc 81.27\tPrec [100.0, 0.0]\n",
      "Test: [30/63]\tTime 0.172 (5.273)\tLoss 0.3008 (0.3412)\tAcc 81.34\tPrec [99.81, 10.81]\n",
      "Test: [40/63]\tTime 20.685 (5.671)\tLoss 0.2501 (0.3233)\tAcc 83.98\tPrec [96.73, 63.34]\n",
      "Test: [50/63]\tTime 0.169 (5.522)\tLoss 0.2614 (0.3118)\tAcc 85.62\tPrec [93.88, 76.94]\n",
      "Test: [60/63]\tTime 14.593 (5.665)\tLoss 0.2798 (0.3048)\tAcc 86.85\tPrec [91.47, 83.22]\n",
      " * Acc 86.99\tPrec [91.12, 83.86]\n",
      "Epoch [7] Learning rate: 0.0001\n",
      "Epoch: [7][0/250]\tTime 22.185 (22.185)\tData 21.902 (21.902)\tLoss 0.2424 (0.2424)\tAcc 89.45\tPrec [91.23, 88.03]\n",
      "Epoch: [7][10/250]\tTime 0.516 (6.306)\tData 0.000 (5.851)\tLoss 0.2151 (0.2383)\tAcc 89.28\tPrec [93.94, 85.7]\n",
      "Epoch: [7][20/250]\tTime 21.084 (6.485)\tData 20.791 (6.032)\tLoss 0.2192 (0.2313)\tAcc 89.66\tPrec [94.31, 85.98]\n",
      "Epoch: [7][30/250]\tTime 0.518 (5.876)\tData 0.000 (5.423)\tLoss 0.2509 (0.2335)\tAcc 89.72\tPrec [94.25, 86.09]\n",
      "Epoch: [7][40/250]\tTime 21.320 (6.105)\tData 21.029 (5.653)\tLoss 0.1908 (0.2343)\tAcc 89.85\tPrec [94.33, 86.29]\n",
      "Epoch: [7][50/250]\tTime 0.516 (5.819)\tData 0.000 (5.363)\tLoss 0.2490 (0.2378)\tAcc 89.79\tPrec [94.35, 86.19]\n",
      "Epoch: [7][60/250]\tTime 21.609 (5.974)\tData 21.300 (5.519)\tLoss 0.2624 (0.2395)\tAcc 89.73\tPrec [94.35, 86.15]\n",
      "Epoch: [7][70/250]\tTime 0.515 (5.847)\tData 0.000 (5.392)\tLoss 0.1968 (0.2396)\tAcc 89.63\tPrec [94.1, 86.16]\n",
      "Epoch: [7][80/250]\tTime 21.177 (5.954)\tData 20.886 (5.499)\tLoss 0.2526 (0.2423)\tAcc 89.46\tPrec [94.1, 85.89]\n",
      "Epoch: [7][90/250]\tTime 2.356 (5.827)\tData 2.071 (5.378)\tLoss 0.2223 (0.2418)\tAcc 89.53\tPrec [94.15, 86.01]\n",
      "Epoch: [7][100/250]\tTime 18.335 (5.894)\tData 18.042 (5.449)\tLoss 0.1964 (0.2414)\tAcc 89.60\tPrec [94.35, 86.01]\n",
      "Epoch: [7][110/250]\tTime 4.804 (5.819)\tData 4.529 (5.385)\tLoss 0.2735 (0.2415)\tAcc 89.58\tPrec [94.29, 86.0]\n",
      "Epoch: [7][120/250]\tTime 15.872 (5.848)\tData 15.581 (5.420)\tLoss 0.2384 (0.2402)\tAcc 89.62\tPrec [94.28, 86.05]\n",
      "Epoch: [7][130/250]\tTime 5.035 (5.800)\tData 4.759 (5.378)\tLoss 0.2741 (0.2402)\tAcc 89.61\tPrec [94.25, 86.05]\n",
      "Epoch: [7][140/250]\tTime 15.706 (5.828)\tData 15.412 (5.411)\tLoss 0.1718 (0.2403)\tAcc 89.64\tPrec [94.2, 86.15]\n",
      "Epoch: [7][150/250]\tTime 5.711 (5.787)\tData 5.435 (5.373)\tLoss 0.2702 (0.2415)\tAcc 89.55\tPrec [94.28, 85.97]\n",
      "Epoch: [7][160/250]\tTime 14.855 (5.809)\tData 14.566 (5.398)\tLoss 0.2038 (0.2407)\tAcc 89.59\tPrec [94.31, 86.0]\n",
      "Epoch: [7][170/250]\tTime 7.512 (5.784)\tData 7.233 (5.378)\tLoss 0.2762 (0.2403)\tAcc 89.61\tPrec [94.33, 86.02]\n",
      "Epoch: [7][180/250]\tTime 14.502 (5.801)\tData 14.192 (5.396)\tLoss 0.2441 (0.2404)\tAcc 89.62\tPrec [94.41, 85.99]\n",
      "Epoch: [7][190/250]\tTime 8.872 (5.787)\tData 8.590 (5.383)\tLoss 0.2630 (0.2409)\tAcc 89.62\tPrec [94.38, 86.01]\n",
      "Epoch: [7][200/250]\tTime 13.159 (5.791)\tData 12.865 (5.386)\tLoss 0.2499 (0.2415)\tAcc 89.58\tPrec [94.36, 85.96]\n",
      "Epoch: [7][210/250]\tTime 8.748 (5.778)\tData 8.471 (5.374)\tLoss 0.2666 (0.2418)\tAcc 89.58\tPrec [94.39, 85.95]\n",
      "Epoch: [7][220/250]\tTime 11.948 (5.783)\tData 11.649 (5.379)\tLoss 0.2326 (0.2414)\tAcc 89.62\tPrec [94.43, 85.99]\n",
      "Epoch: [7][230/250]\tTime 8.621 (5.773)\tData 8.342 (5.372)\tLoss 0.2556 (0.2414)\tAcc 89.64\tPrec [94.43, 86.03]\n",
      "Epoch: [7][240/250]\tTime 12.445 (5.774)\tData 12.151 (5.375)\tLoss 0.2403 (0.2415)\tAcc 89.65\tPrec [94.45, 86.03]\n",
      "Test: [0/63]\tTime 12.087 (12.087)\tLoss 0.3476 (0.3476)\tAcc 82.03\tPrec [100.0, 0.0]\n",
      "Test: [10/63]\tTime 0.176 (5.151)\tLoss 0.3532 (0.3966)\tAcc 80.22\tPrec [100.0, 0.0]\n",
      "Test: [20/63]\tTime 17.233 (5.632)\tLoss 0.4067 (0.4010)\tAcc 80.23\tPrec [100.0, 0.0]\n",
      "Test: [30/63]\tTime 0.170 (5.426)\tLoss 0.2450 (0.3990)\tAcc 80.09\tPrec [99.79, 10.15]\n",
      "Test: [40/63]\tTime 19.109 (5.683)\tLoss 0.1934 (0.3525)\tAcc 83.57\tPrec [97.52, 62.33]\n",
      "Test: [50/63]\tTime 0.169 (5.598)\tLoss 0.1876 (0.3234)\tAcc 85.78\tPrec [95.52, 76.21]\n",
      "Test: [60/63]\tTime 13.729 (5.697)\tLoss 0.2299 (0.3046)\tAcc 87.24\tPrec [93.56, 82.61]\n",
      " * Acc 87.42\tPrec [93.3, 83.27]\n",
      "Epoch [8] Learning rate: 0.0001\n",
      "Epoch: [8][0/250]\tTime 20.883 (20.883)\tData 20.586 (20.586)\tLoss 0.1559 (0.1559)\tAcc 93.75\tPrec [97.37, 90.85]\n",
      "Epoch: [8][10/250]\tTime 1.499 (6.187)\tData 1.217 (5.840)\tLoss 0.2318 (0.1996)\tAcc 91.83\tPrec [95.15, 89.07]\n",
      "Epoch: [8][20/250]\tTime 19.229 (6.353)\tData 18.935 (5.990)\tLoss 0.1687 (0.2080)\tAcc 91.18\tPrec [94.9, 88.17]\n",
      "Epoch: [8][30/250]\tTime 0.523 (5.896)\tData 0.001 (5.521)\tLoss 0.1926 (0.2045)\tAcc 91.46\tPrec [94.7, 88.86]\n",
      "Epoch: [8][40/250]\tTime 17.230 (6.019)\tData 16.932 (5.636)\tLoss 0.2608 (0.2105)\tAcc 91.23\tPrec [94.39, 88.69]\n",
      "Epoch: [8][50/250]\tTime 0.521 (5.844)\tData 0.000 (5.458)\tLoss 0.2287 (0.2138)\tAcc 91.05\tPrec [94.31, 88.43]\n",
      "Epoch: [8][60/250]\tTime 14.976 (5.894)\tData 14.684 (5.506)\tLoss 0.2355 (0.2144)\tAcc 91.00\tPrec [94.12, 88.49]\n",
      "Epoch: [8][70/250]\tTime 0.519 (5.823)\tData 0.000 (5.432)\tLoss 0.1790 (0.2124)\tAcc 91.17\tPrec [94.45, 88.57]\n",
      "Epoch: [8][80/250]\tTime 12.228 (5.826)\tData 11.930 (5.433)\tLoss 0.2571 (0.2119)\tAcc 91.14\tPrec [94.42, 88.54]\n",
      "Epoch: [8][90/250]\tTime 0.518 (5.810)\tData 0.000 (5.417)\tLoss 0.2240 (0.2125)\tAcc 91.09\tPrec [94.36, 88.53]\n",
      "Epoch: [8][100/250]\tTime 11.805 (5.803)\tData 11.527 (5.408)\tLoss 0.1892 (0.2136)\tAcc 91.01\tPrec [94.36, 88.38]\n",
      "Epoch: [8][110/250]\tTime 0.516 (5.781)\tData 0.000 (5.385)\tLoss 0.1776 (0.2147)\tAcc 91.00\tPrec [94.4, 88.31]\n",
      "Epoch: [8][120/250]\tTime 14.695 (5.801)\tData 14.406 (5.405)\tLoss 0.1634 (0.2159)\tAcc 90.97\tPrec [94.38, 88.26]\n",
      "Epoch: [8][130/250]\tTime 0.519 (5.765)\tData 0.000 (5.368)\tLoss 0.2165 (0.2164)\tAcc 90.92\tPrec [94.37, 88.18]\n",
      "Epoch: [8][140/250]\tTime 16.526 (5.796)\tData 16.249 (5.399)\tLoss 0.2205 (0.2151)\tAcc 91.00\tPrec [94.39, 88.3]\n",
      "Epoch: [8][160/250]\tTime 17.887 (5.795)\tData 17.592 (5.397)\tLoss 0.2013 (0.2144)\tAcc 91.07\tPrec [94.45, 88.38]\n",
      "Epoch: [8][170/250]\tTime 0.519 (5.755)\tData 0.000 (5.357)\tLoss 0.2007 (0.2152)\tAcc 91.01\tPrec [94.42, 88.29]\n",
      "Epoch: [8][180/250]\tTime 17.039 (5.790)\tData 16.764 (5.391)\tLoss 0.2510 (0.2163)\tAcc 90.96\tPrec [94.44, 88.2]\n",
      "Epoch: [8][190/250]\tTime 0.513 (5.750)\tData 0.000 (5.351)\tLoss 0.1717 (0.2161)\tAcc 90.94\tPrec [94.5, 88.13]\n",
      "Epoch: [8][200/250]\tTime 17.660 (5.782)\tData 17.361 (5.383)\tLoss 0.2206 (0.2159)\tAcc 90.97\tPrec [94.54, 88.14]\n",
      "Epoch: [8][210/250]\tTime 0.518 (5.747)\tData 0.000 (5.348)\tLoss 0.2421 (0.2158)\tAcc 90.99\tPrec [94.54, 88.17]\n",
      "Epoch: [8][220/250]\tTime 18.827 (5.779)\tData 18.532 (5.380)\tLoss 0.2380 (0.2161)\tAcc 90.97\tPrec [94.56, 88.12]\n",
      "Epoch: [8][230/250]\tTime 0.515 (5.746)\tData 0.000 (5.348)\tLoss 0.1838 (0.2163)\tAcc 90.93\tPrec [94.46, 88.13]\n",
      "Epoch: [8][240/250]\tTime 15.726 (5.767)\tData 15.427 (5.368)\tLoss 0.2388 (0.2171)\tAcc 90.89\tPrec [94.5, 88.02]\n",
      "Test: [0/63]\tTime 11.912 (11.912)\tLoss 0.3702 (0.3702)\tAcc 82.03\tPrec [100.0, 0.0]\n",
      "Test: [10/63]\tTime 0.665 (4.801)\tLoss 0.3548 (0.4164)\tAcc 81.04\tPrec [100.0, 0.0]\n",
      "Test: [20/63]\tTime 19.931 (5.580)\tLoss 0.4786 (0.4238)\tAcc 80.92\tPrec [100.0, 0.0]\n",
      "Test: [30/63]\tTime 0.171 (5.241)\tLoss 0.2908 (0.4230)\tAcc 80.86\tPrec [99.84, 10.66]\n",
      "Test: [40/63]\tTime 18.109 (5.657)\tLoss 0.1878 (0.3689)\tAcc 84.10\tPrec [97.5, 63.19]\n",
      "Test: [50/63]\tTime 1.078 (5.510)\tLoss 0.1876 (0.3354)\tAcc 86.04\tPrec [95.22, 76.81]\n",
      "Test: [60/63]\tTime 11.369 (5.657)\tLoss 0.2242 (0.3138)\tAcc 87.26\tPrec [92.85, 83.04]\n",
      " * Acc 87.46\tPrec [92.63, 83.7]\n",
      "Epoch [9] Learning rate: 0.0001\n",
      "Epoch: [9][0/250]\tTime 21.668 (21.668)\tData 21.323 (21.323)\tLoss 0.1746 (0.1746)\tAcc 93.36\tPrec [99.02, 89.61]\n",
      "Epoch: [9][10/250]\tTime 0.513 (6.256)\tData 0.000 (5.796)\tLoss 0.1860 (0.1840)\tAcc 92.47\tPrec [95.75, 89.77]\n",
      "Epoch: [9][20/250]\tTime 21.166 (6.490)\tData 20.869 (6.035)\tLoss 0.2030 (0.1885)\tAcc 92.45\tPrec [95.34, 90.15]\n",
      "Epoch: [9][30/250]\tTime 0.513 (5.895)\tData 0.001 (5.434)\tLoss 0.1863 (0.1838)\tAcc 92.68\tPrec [95.24, 90.56]\n",
      "Epoch: [9][40/250]\tTime 19.947 (6.079)\tData 19.647 (5.626)\tLoss 0.1761 (0.1829)\tAcc 92.71\tPrec [95.06, 90.76]\n",
      "Epoch: [9][50/250]\tTime 0.515 (5.815)\tData 0.000 (5.372)\tLoss 0.1274 (0.1828)\tAcc 92.67\tPrec [95.18, 90.6]\n"
     ]
    }
   ],
   "source": [
    "# !python -m torch.distributed.launch --nproc_per_node=8 classify.py train --arch drn_d_38 -j 8 ~/dataset/ --epochs 50\n",
    "!python classify.py train --arch drn_c_26 -j 4 ~/dataset/ --epochs 10 --resume checkpoint_latest.pth.tar --lr .0001\n",
    "# !python classify.py train --arch drn_c_26 -j 4 ~/dataset/ --epochs 10 --lr .0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlikely-click",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# lr = .01, adam\n",
    "# Training_Losses = [0.8073884157729748, 0.6972268387964972, 0.7018214403989474, 0.7018083767226206, 0.6961493333293793]\n",
    "# Validation_Losses = [815.2103271484375, 0.8441811800003052, 0.716885507106781, 0.693462073802948, 0.6939836144447327]\n",
    "# plt.plot(Training_Losses)\n",
    "# plt.plot(Validation_Losses)\n",
    "# sns.lineplot(list(range(5)), Training_Losses)\n",
    "# sns.lineplot(list(range(5)), Validation_Losses)\n",
    "\n",
    "# # # lr = .1\n",
    "# Training_Losses: [1.2809674800883655, 0.6956474380845874, 0.6943234133177767, 0.6944891460250485, 0.6942407902013978]\n",
    "# Validation_Losses: [1885.666259765625, 1.0386748313903809, 0.7603570818901062, 0.6943628787994385, 0.6939992308616638]\n",
    "# plt.plot(Training_Losses)\n",
    "# plt.plot(Validation_Losses)\n",
    "    \n",
    "# # # lr = .0001\n",
    "# Training_Losses = [0.6227307069239428, 0.5982465861306026, 0.5753281735706918, 0.5445946155424195, 0.4969190442206002, 0.4404183055564316, 0.37097120569067693, 0.30068901294269174, 0.25268726659194163, 0.22078772079978526, 0.18435736870302188, 0.12641071757472144, 0.11088151365674011, 0.1137006409561651, 0.08535260703253938]\n",
    "# Validation_Losses = [0.6398677229881287, 0.5365579724311829, 0.5916299223899841, 0.9598435163497925, 0.5804687738418579, 0.7908967733383179, 1.7546828985214233, 1.1634283065795898, 0.5872610211372375, 0.8261275887489319, 0.8636678457260132, 0.9018855690956116, 1.9972766637802124, 0.737250804901123, 0.962520956993103]\n",
    "# sns.lineplot(list(range(len(Training_Losses))), Training_Losses)\n",
    "# sns.lineplot(list(range(len(Training_Losses))), Validation_Losses)\n",
    "Training_Losses= [0.6423899541413736, 0.4710868365523285, 0.4616844617733945, 0.45210057935980713, 0.4483424580384855, 0.4417781812499885, 0.41718768551221874, 0.3644165815529275, 0.3209927497986752, 0.28457082486365587]\n",
    "Validation_Losses= [0.5100556163634795, 0.45708035029762367, 0.4608456277201623, 0.44951926370561424, 0.46411477138429375, 0.4681821265215859, 0.5253984027186273, 0.36634321328450586, 0.3504126114824949, 0.41745512481917113]\n",
    "sns.lineplot(list(range(len(Training_Losses))), Training_Losses)\n",
    "sns.lineplot(list(range(len(Training_Losses))), Validation_Losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "young-brick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify.py test --arch drn_c_26 -j 4 /home/jupyter/dataset/ --resume model_best.pth.tar --print-freq=1\n",
      "Namespace(arch='drn_c_26', batch_size=256, check_freq=10, cmd='test', crop_size=224, data='/home/jupyter/dataset/', epochs=90, evaluate=False, lr=1, lr_adjust='step', momentum=0.9, num_classes=2, pretrained=False, print_freq=1, resume='model_best.pth.tar', scale_size=256, start_epoch=0, step_ratio=0.1, weight_decay=0.0001, workers=4)\n",
      "=> loading checkpoint 'model_best.pth.tar'\n",
      "=> loaded checkpoint 'model_best.pth.tar' (epoch 6)\n",
      "Test: [0/8]\tTime 38.772 (38.772)\tLoss 1.9326 (1.9326)\tAcc 2.73\tPrec [100.0, 0.0]\n",
      "Test: [1/8]\tTime 0.193 (19.483)\tLoss 1.9119 (1.9223)\tAcc 2.54\tPrec [100.0, 0.0]\n",
      "Test: [2/8]\tTime 0.169 (13.045)\tLoss 1.9352 (1.9266)\tAcc 2.08\tPrec [100.0, 0.0]\n",
      "Test: [3/8]\tTime 0.173 (9.827)\tLoss 1.8198 (1.8999)\tAcc 3.71\tPrec [100.0, 1.69]\n",
      "Test: [4/8]\tTime 9.521 (9.766)\tLoss 0.1663 (1.5532)\tAcc 22.73\tPrec [87.5, 21.5]\n",
      "Test: [5/8]\tTime 0.174 (8.167)\tLoss 0.1872 (1.3255)\tAcc 35.42\tPrec [77.78, 34.66]\n",
      "Test: [6/8]\tTime 0.168 (7.024)\tLoss 0.1967 (1.1642)\tAcc 44.48\tPrec [70.0, 44.04]\n",
      "Test: [7/8]\tTime 0.703 (6.234)\tLoss 0.1917 (1.0601)\tAcc 50.32\tPrec [65.62, 50.08]\n",
      " * Acc 50.32\tPrec [65.62, 50.08]\n"
     ]
    }
   ],
   "source": [
    "!python3 classify.py test --arch drn_c_26 -j 4 ~/dataset/ --resume model_best.pth.tar --print-freq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "warming-memphis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify.py test --arch drn_c_26 -j 4 /home/jupyter/dataset/ --resume checkpoint_latest.pth.tar --print-freq=1\n",
      "Namespace(arch='drn_c_26', batch_size=256, check_freq=10, cmd='test', crop_size=224, data='/home/jupyter/dataset/', epochs=90, evaluate=False, lr=1, lr_adjust='step', momentum=0.9, num_classes=2, pretrained=False, print_freq=1, resume='checkpoint_latest.pth.tar', scale_size=256, start_epoch=0, step_ratio=0.1, weight_decay=0.0001, workers=4)\n",
      "=> loading checkpoint 'checkpoint_latest.pth.tar'\n",
      "=> loaded checkpoint 'checkpoint_latest.pth.tar' (epoch 9)\n",
      "Test: [0/8]\tTime 38.578 (38.578)\tLoss 1.3847 (1.3847)\tAcc 4.30\tPrec [100.0, 0.0]\n",
      "Test: [1/8]\tTime 0.205 (19.391)\tLoss 1.3752 (1.3799)\tAcc 4.30\tPrec [100.0, 0.0]\n",
      "Test: [2/8]\tTime 0.170 (12.984)\tLoss 1.3897 (1.3832)\tAcc 4.04\tPrec [100.0, 0.0]\n",
      "Test: [3/8]\tTime 0.173 (9.781)\tLoss 1.3151 (1.3662)\tAcc 5.08\tPrec [94.87, 1.52]\n",
      "Test: [4/8]\tTime 8.748 (9.575)\tLoss 0.3124 (1.1554)\tAcc 23.59\tPrec [82.22, 21.46]\n",
      "Test: [5/8]\tTime 0.169 (8.007)\tLoss 0.3046 (1.0136)\tAcc 36.13\tPrec [77.08, 34.81]\n",
      "Test: [6/8]\tTime 0.169 (6.887)\tLoss 0.3248 (0.9152)\tAcc 44.87\tPrec [67.27, 44.16]\n",
      "Test: [7/8]\tTime 0.709 (6.115)\tLoss 0.3304 (0.8526)\tAcc 50.52\tPrec [61.67, 50.18]\n",
      " * Acc 50.52\tPrec [61.67, 50.18]\n"
     ]
    }
   ],
   "source": [
    "!python3 classify.py test --arch drn_c_26 -j 4 ~/dataset/ --resume checkpoint_latest.pth.tar --print-freq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "middle-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify.py test --arch drn_c_26 -j 4 /home/jupyter/dataset/ --resume origin.pth.tar --print-freq=1\n",
      "Namespace(arch='drn_c_26', batch_size=256, check_freq=10, cmd='test', crop_size=224, data='/home/jupyter/dataset/', epochs=90, evaluate=False, lr=1, lr_adjust='step', momentum=0.9, num_classes=2, pretrained=False, print_freq=1, resume='origin.pth.tar', scale_size=256, start_epoch=0, step_ratio=0.1, weight_decay=0.0001, workers=4)\n",
      "=> loading checkpoint 'origin.pth.tar'\n",
      "=> loaded checkpoint 'origin.pth.tar' (epoch 16)\n",
      "Test: [0/8]\tTime 37.942 (37.942)\tLoss 2.3678 (2.3678)\tAcc 28.12\tPrec [100.0, 0.0]\n",
      "Test: [1/8]\tTime 0.184 (19.063)\tLoss 2.4374 (2.4026)\tAcc 25.78\tPrec [100.0, 0.0]\n",
      "Test: [2/8]\tTime 0.170 (12.765)\tLoss 2.9113 (2.5722)\tAcc 23.96\tPrec [100.0, 0.0]\n",
      "Test: [3/8]\tTime 0.173 (9.617)\tLoss 2.7317 (2.6121)\tAcc 24.22\tPrec [99.15, 1.9]\n",
      "Test: [4/8]\tTime 10.132 (9.720)\tLoss 0.2582 (2.1413)\tAcc 37.34\tPrec [89.27, 24.04]\n",
      "Test: [5/8]\tTime 0.174 (8.129)\tLoss 0.1920 (1.8164)\tAcc 46.42\tPrec [82.62, 38.28]\n",
      "Test: [6/8]\tTime 0.168 (6.992)\tLoss 0.2217 (1.5886)\tAcc 52.46\tPrec [74.92, 47.74]\n",
      "Test: [7/8]\tTime 0.641 (6.198)\tLoss 0.2273 (1.4428)\tAcc 56.50\tPrec [70.18, 53.79]\n",
      " * Acc 56.50\tPrec [70.18, 53.79]\n"
     ]
    }
   ],
   "source": [
    "!python3 classify.py test --arch drn_c_26 -j 4 ~/dataset/ --resume origin.pth.tar --print-freq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-david",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
